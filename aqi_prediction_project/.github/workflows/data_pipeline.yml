name: AQI Data Pipeline

on:
  schedule:
    # Run every hour for data collection
    - cron: '0 * * * *'
  # Also run on manual trigger
  workflow_dispatch:
    inputs:
      run_type:
        description: 'Type of run'
        required: true
        default: 'data_collection'
        type: choice
        options:
        - data_collection
        - model_training
        - full_pipeline

jobs:
  data_collection:
    if: github.event_name == 'schedule' || github.event.inputs.run_type == 'data_collection' || github.event.inputs.run_type == 'full_pipeline'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        cd aqi_prediction_project
        pip install -r requirements.txt
        
    - name: Collect real-time data
      run: |
        cd aqi_prediction_project
        python3 -c "
        from real_time_data import RealTimeDataFetcher
        import json
        from datetime import datetime
        
        fetcher = RealTimeDataFetcher()
        data = fetcher.get_current_data()
        
        if data:
            # Save data to file
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'data/real_time_data_{timestamp}.json'
            
            with open(filename, 'w') as f:
                json.dump(data, f, indent=2)
            
            print(f'Data saved to {filename}')
            print(f'Temperature: {data.get(\"temperature\", \"N/A\")}°C')
            print(f'Humidity: {data.get(\"humidity\", \"N/A\")}%')
            print(f'PM2.5: {data.get(\"pm25\", \"N/A\")} μg/m³')
        else:
            print('Failed to collect data')
            exit(1)
        "
        
    - name: Upload data artifacts
      uses: actions/upload-artifact@v3
      with:
        name: real-time-data
        path: aqi_prediction_project/data/real_time_data_*.json
        retention-days: 7

  model_training:
    if: github.event.inputs.run_type == 'model_training' || github.event.inputs.run_type == 'full_pipeline'
    runs-on: ubuntu-latest
    needs: data_collection
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        cd aqi_prediction_project
        pip install -r requirements.txt
        
    - name: Download historical data
      run: |
        cd aqi_prediction_project
        # Download historical data if not present
        if [ ! -f "data/karachi_weather_1year.csv" ]; then
          python3 collect_yearly_data.py
        fi
        
    - name: Train model
      run: |
        cd aqi_prediction_project
        python3 -c "
        import pandas as pd
        import numpy as np
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.linear_model import Ridge
        from sklearn.preprocessing import StandardScaler
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        import joblib
        import os
        
        # Load and prepare data (simplified version)
        print('Loading historical data...')
        weather_df = pd.read_csv('data/karachi_weather_1year.csv')
        air_quality_df = pd.read_csv('data/karachi_air_quality_1year.csv')
        
        # Merge datasets
        df = pd.merge(weather_df, air_quality_df, on='time', how='inner')
        
        # Simple feature engineering
        df['hour'] = pd.to_datetime(df['time']).dt.hour
        df['day'] = pd.to_datetime(df['time']).dt.day
        df['month'] = pd.to_datetime(df['time']).dt.month
        df['weekday'] = pd.to_datetime(df['time']).dt.weekday
        
        # Select features
        feature_cols = ['temperature_2m', 'relative_humidity_2m', 'surface_pressure', 
                       'wind_speed_10m', 'wind_direction_10m', 'precipitation',
                       'pm10', 'pm2_5', 'co', 'no2', 'o3', 'so2',
                       'hour', 'day', 'month', 'weekday']
        
        X = df[feature_cols].fillna(0)
        y = df['pm2_5']  # Using PM2.5 as target for simplicity
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Train model
        model = Ridge(alpha=1.0)
        model.fit(X_train_scaled, y_train)
        
        # Evaluate
        y_pred = model.predict(X_test_scaled)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f'Model Performance:')
        print(f'RMSE: {rmse:.4f}')
        print(f'MAE: {mae:.4f}')
        print(f'R2: {r2:.4f}')
        
        # Save model and scaler
        os.makedirs('models', exist_ok=True)
        joblib.dump(model, 'models/ridge_regression_best.pkl')
        joblib.dump(scaler, 'models/scaler.pkl')
        
        print('Model saved successfully!')
        "
        
    - name: Upload model artifacts
      uses: actions/upload-artifact@v3
      with:
        name: trained-model
        path: aqi_prediction_project/models/
        retention-days: 30

  api_deployment:
    if: github.event.inputs.run_type == 'full_pipeline'
    runs-on: ubuntu-latest
    needs: [data_collection, model_training]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        cd aqi_prediction_project
        pip install -r requirements.txt
        
    - name: Test API
      run: |
        cd aqi_prediction_project
        python3 -c "
        from api import app
        import threading
        import time
        import requests
        
        # Start API in background
        def run_api():
            app.run(host='0.0.0.0', port=5000, debug=False)
        
        api_thread = threading.Thread(target=run_api)
        api_thread.daemon = True
        api_thread.start()
        
        # Wait for API to start
        time.sleep(5)
        
        # Test API endpoints
        try:
            response = requests.get('http://localhost:5000/health', timeout=10)
            if response.status_code == 200:
                print('✅ API health check passed')
            else:
                print('❌ API health check failed')
                exit(1)
                
            response = requests.get('http://localhost:5000/predict/single', timeout=10)
            if response.status_code == 200:
                data = response.json()
                print(f'✅ Prediction test passed: AQI = {data.get(\"aqi\", \"N/A\")}')
            else:
                print('❌ Prediction test failed')
                exit(1)
                
        except Exception as e:
            print(f'❌ API test failed: {e}')
            exit(1)
        "
        
    - name: Deploy to cloud (placeholder)
      run: |
        echo "This would deploy to your cloud provider (AWS, GCP, Azure, etc.)"
        echo "For now, this is a placeholder for deployment steps"